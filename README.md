# Pizza-Restaurant-Review-Analysis-Rag
A Retrieval-Augmented Generation (RAG) system for Pizza Restaurant Review Analysis using Ollama and ChromaDB. Combines local LLM inference with mxbai-embed-large embeddings to analyze, summarize, and answer customer feedback â€” completely offline and privacy-friendly. ğŸ•ğŸ¤–
ğŸ• Pizza Restaurant Review Analysis using RAG and Ollama
ğŸ“– Overview

This project implements a Retrieval-Augmented Generation (RAG) pipeline for analyzing and summarizing restaurant reviews, specifically focused on a pizza restaurant ğŸ•.
It combines Ollamaâ€™s local LLM inference with semantic search embeddings (mxbai-embed-large) to provide meaningful insights about customer experiences â€” completely offline and privacy-friendly.

ğŸš€ Features

âœ… Local LLM inference via Ollama

ğŸ§  Text embeddings using mxbai-embed-large

ğŸ” Vector-based retrieval using ChromaDB

ğŸ’¬ Context-aware Q&A over restaurant reviews

ğŸ“Š Includes a realistic restaurant review dataset

ğŸ”’ 100% offline â€” no API keys or cloud dependency

ğŸ§  System Architecture

RAG Pipeline Flow:

Document Ingestion â€“ Reads and cleans restaurant review data

Embedding Generation â€“ Encodes text using mxbai-embed-large

Vector Storage & Retrieval â€“ Stores embeddings in ChromaDB for semantic similarity search

LLM Response Generation â€“ Uses Ollama (e.g., llama3, mistral) to generate contextual answers

ğŸ“ pizza-restaurant-review-analysis/
â”‚
â”œâ”€â”€ ğŸ“„ main.py                     # Main entry point for the RAG pipeline
â”œâ”€â”€ ğŸ“„ vector.py                   # Handles embedding and vector storage (mxbai-embed-large)
â”œâ”€â”€ ğŸ“ realistic_restaurant_reviews/  # Folder containing sample restaurant review data
â”œâ”€â”€ ğŸ“ chrome_langchain_db/        # ChromaDB vector database
â”‚   â”œâ”€â”€ chroma.sqlite3
â”‚   â””â”€â”€ 8b8d4954a... (vector data)
â”œâ”€â”€ ğŸ“„ requirements.txt            # Python dependencies
â”œâ”€â”€ ğŸ“ venv/                       # Virtual environment
â””â”€â”€ âš™ï¸ pyvenv.cfg

ğŸ§© Installation
1ï¸âƒ£ Clone the Repository
git clone https://github.com/yourusername/pizza-restaurant-review-analysis.git
cd pizza-restaurant-review-analysis

2ï¸âƒ£ Create and Activate Virtual Environment
python -m venv venv
# Windows
venv\Scripts\activate
# macOS/Linux
source venv/bin/activate

3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

4ï¸âƒ£ Install and Run Ollama

Download Ollama from ğŸ‘‰ https://ollama.ai

Start the Ollama service:

ollama serve


Pull the required models:

ollama pull llama3
ollama pull mxbai-embed-large

â–¶ï¸ Running the Application

To start the RAG system:

python main.py


Youâ€™ll be prompted to enter a question, for example:

â€œWhat do customers say about pizza quality?â€

The system will:

Retrieve the most relevant reviews using mxbai-embed-large

Generate a natural-language summary using Ollama

ğŸ’¬ Example Usage
ğŸ§  Input:
Enter your query: What do customers think about pizza delivery service?

âš™ï¸ Internal Steps:

Retrieves similar reviews from ChromaDB

Uses mxbai-embed-large embeddings to find related text chunks

Sends context + question to the Ollama LLM (llama3)

ğŸ’¡ Output:
Most customers appreciated the quick and warm delivery of pizzas. 
Several reviews mentioned that orders arrived within 25â€“30 minutes, 
while a few noted slight delays during weekends. 
Overall, the delivery service is rated highly for reliability and speed.

ğŸ§° Requirements

Python 3.10+

Ollama installed locally

Models:

llama3 (or any local LLM supported by Ollama)

mxbai-embed-large (embedding model)

Dependencies listed in requirements.txt

ğŸ“ˆ Future Enhancements

ğŸ“Š Add Streamlit dashboard for visual insights

ğŸ¤– Integrate sentiment classification per review

ğŸ½ï¸ Extend to multiple restaurant datasets

ğŸ³ Add Docker support for deployment
